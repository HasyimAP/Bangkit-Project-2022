{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Food Scanning","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nimport PIL\nfrom PIL import Image\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nfrom sklearn.model_selection import train_test_split","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Image","metadata":{}},{"cell_type":"code","source":"from keras_preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = \"../input/food-ingredients/Data/train\"\nVALIDATION_DIR = \"../input/food-ingredients/Data/val\"\n\n# Make Labels\nclasses = os.listdir(TRAINING_DIR)\nwith open('food_label.txt', 'w') as f:\n    for food_class in classes:\n        f.write(f'{food_class}\\n')\n\ntrain_ds = ImageDataGenerator(\n      rescale = 1./255,\n      rotation_range=45,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest',\n      )\n\ntrain_generator = train_ds.flow_from_directory(directory=TRAINING_DIR,\n                                                batch_size=128,\n                                                class_mode='categorical',\n                                                target_size=(256, 256))\n\ntest_ds = ImageDataGenerator(\n      rescale = 1./255)\nvalidation_generator = test_ds.flow_from_directory(directory=VALIDATION_DIR,\n                                                    batch_size=128,\n                                                    class_mode='categorical',\n                                                    target_size=(256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T14:13:52.119808Z","iopub.execute_input":"2022-05-28T14:13:52.120386Z","iopub.status.idle":"2022-05-28T14:14:02.454309Z","shell.execute_reply.started":"2022-05-28T14:13:52.1203Z","shell.execute_reply":"2022-05-28T14:14:02.453571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{}},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    mode='min',\n    restore_best_weights=True\n)\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(128, 128, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    #tf.keras.layers.Dropout(0.7),\n    # The fifth convolution\n    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The sixth convolution\n    #tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    #tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.5),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    #tf.keras.layers.Dropout(0.2),\n    # 320 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(26, activation='softmax')\n])\n\n# Print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:53:24.971527Z","iopub.execute_input":"2022-05-28T02:53:24.971786Z","iopub.status.idle":"2022-05-28T02:53:27.796414Z","shell.execute_reply.started":"2022-05-28T02:53:24.971757Z","shell.execute_reply":"2022-05-28T02:53:27.795684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the training parameters\n\n#opt = keras.optimizers.Adam(learning_rate=0.1)\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:53:32.127965Z","iopub.execute_input":"2022-05-28T02:53:32.128675Z","iopub.status.idle":"2022-05-28T02:53:32.141969Z","shell.execute_reply.started":"2022-05-28T02:53:32.128636Z","shell.execute_reply":"2022-05-28T02:53:32.14114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_generator, epochs=75, validation_data = validation_generator, callbacks = [callbacks])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T02:53:34.741258Z","iopub.execute_input":"2022-05-28T02:53:34.741515Z","iopub.status.idle":"2022-05-28T04:45:54.427441Z","shell.execute_reply.started":"2022-05-28T02:53:34.741486Z","shell.execute_reply":"2022-05-28T04:45:54.426585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Training and Validation","metadata":{}},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.show()\nprint(\"\")\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T04:45:55.853871Z","iopub.execute_input":"2022-05-28T04:45:55.854166Z","iopub.status.idle":"2022-05-28T04:45:56.16542Z","shell.execute_reply.started":"2022-05-28T04:45:55.854126Z","shell.execute_reply":"2022-05-28T04:45:56.164616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save and Convert ","metadata":{}},{"cell_type":"code","source":"#Save the model\n#!mkdir -p saved_model\nmodel.save('saved_model/val_acc8447')\n\n# Convert the model\npath = '/kaggle/working/saved_model/val_acc8447'\nconverter = tf.lite.TFLiteConverter.from_saved_model(path) # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('food_val8447.tflite', 'wb') as f:\n  f.write(tflite_model)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-27T17:51:06.21085Z","iopub.execute_input":"2022-05-27T17:51:06.211175Z","iopub.status.idle":"2022-05-27T17:51:07.335511Z","shell.execute_reply.started":"2022-05-27T17:51:06.211139Z","shell.execute_reply":"2022-05-27T17:51:07.33468Z"},"trusted":true},"execution_count":null,"outputs":[]}]}